{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters:  20479\n"
     ]
    }
   ],
   "source": [
    "with open('the-verdict.txt', \"r\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"Total number of characters: \", len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens:  4649\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "preprocessed = re.split(r'([,.?!\"\\'()_]|--|\\s)', raw_text)\n",
    "preprocessed = [item for item in preprocessed if item.strip()]\n",
    "print(\"Total number of tokens: \", len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  1161\n",
      "Vocabulary:  {'!': 0, '\"': 1, \"'\": 2, '(': 3, ')': 4, ',': 5, '--': 6, '.': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'Ah': 12, 'Among': 13, 'And': 14, 'Are': 15, 'Arrt': 16, 'As': 17, 'At': 18, 'Be': 19, 'Begin': 20, 'Burlington': 21, 'But': 22, 'By': 23, 'Carlo': 24, 'Carlo;': 25, 'Chicago': 26, 'Claude': 27, 'Come': 28, 'Croft': 29, 'Destroyed': 30, 'Devonshire': 31, 'Don': 32, 'Dubarry': 33, 'Emperors': 34, 'Florence': 35, 'For': 36, 'Gallery': 37, 'Gideon': 38, 'Gisburn': 39, 'Gisburns': 40, 'Grafton': 41, 'Greek': 42, 'Grindle': 43, 'Grindle:': 44, 'Grindles': 45, 'HAD': 46, 'Had': 47, 'Hang': 48, 'Has': 49, 'He': 50, 'Her': 51, 'Hermia': 52, 'His': 53, 'How': 54, 'I': 55, 'If': 56, 'In': 57, 'It': 58, 'Jack': 59, 'Jove': 60, 'Just': 61, 'Lord': 62, 'Made': 63, 'Miss': 64, 'Money': 65, 'Monte': 66, 'Moon-dancers': 67, 'Mr': 68, 'Mrs': 69, 'My': 70, 'Never': 71, 'No': 72, 'Now': 73, 'Nutley': 74, 'Of': 75, 'Oh': 76, 'On': 77, 'Once': 78, 'Only': 79, 'Or': 80, 'Perhaps': 81, 'Poor': 82, 'Professional': 83, 'Renaissance': 84, 'Rickham': 85, 'Rickham;': 86, 'Riviera': 87, 'Rome': 88, 'Russian': 89, 'Sevres': 90, 'She': 91, 'Stroud': 92, 'Strouds': 93, 'Suddenly': 94, 'That': 95, 'The': 96, 'Then': 97, 'There': 98, 'There:': 99, 'They': 100, 'This': 101, 'Those': 102, 'Though': 103, 'Thwing': 104, 'Thwings': 105, 'To': 106, 'Usually': 107, 'Venetian': 108, 'Victor': 109, 'Was': 110, 'We': 111, 'Well': 112, 'What': 113, 'When': 114, 'Why': 115, 'Yes': 116, 'You': 117, '_': 118, 'a': 119, 'abdication': 120, 'able': 121, 'about': 122, 'about;': 123, 'above': 124, 'abruptly': 125, 'absolute': 126, 'absorbed': 127, 'absurdity': 128, 'academic': 129, 'accuse': 130, 'accustomed': 131, 'across': 132, 'activity': 133, 'add': 134, 'added': 135, 'admirers': 136, 'adopted': 137, 'adulation': 138, 'advance': 139, 'aesthetic': 140, 'affect': 141, 'afraid': 142, 'after': 143, 'afterward': 144, 'again': 145, 'ago': 146, 'ah': 147, 'air': 148, 'alive': 149, 'all': 150, 'almost': 151, 'alone': 152, 'along': 153, 'always': 154, 'am': 155, 'amazement': 156, 'amid': 157, 'among': 158, 'amplest': 159, 'amusing': 160, 'an': 161, 'and': 162, 'another': 163, 'answer': 164, 'answered': 165, 'any': 166, 'anything': 167, 'anywhere': 168, 'apparent': 169, 'apparently': 170, 'appearance': 171, 'appeared': 172, 'appointed': 173, 'are': 174, 'arm': 175, 'arm-chair': 176, 'arm-chairs': 177, 'arms': 178, 'art': 179, 'articles': 180, 'artist': 181, 'as': 182, 'aside': 183, 'asked': 184, 'at': 185, 'atmosphere': 186, 'atom': 187, 'attack': 188, 'attention': 189, 'attention;': 190, 'attitude': 191, 'audacities': 192, 'away': 193, 'awful': 194, 'axioms': 195, 'azaleas': 196, 'back': 197, 'background': 198, 'balance': 199, 'balancing': 200, 'balustraded': 201, 'basking': 202, 'bath-rooms': 203, 'be': 204, 'beaming': 205, 'bean-stalk': 206, 'bear': 207, 'beard': 208, 'beauty': 209, 'became': 210, 'because': 211, 'becoming': 212, 'bed': 213, 'been': 214, 'before': 215, 'began': 216, 'begun': 217, 'behind': 218, 'being': 219, 'believed': 220, 'beneath': 221, 'bespoke': 222, 'better': 223, 'better;': 224, 'between': 225, 'big': 226, 'bits': 227, 'bitterness': 228, 'blocked': 229, 'born': 230, 'borne': 231, 'boudoir': 232, 'bravura': 233, 'break': 234, 'breaking': 235, 'breathing': 236, 'bric-a-brac': 237, 'briefly': 238, 'brings': 239, 'bronzes': 240, 'brought': 241, 'brown': 242, 'brush': 243, 'bull': 244, 'business': 245, 'but': 246, 'buying': 247, 'by': 248, 'called': 249, 'came': 250, 'can': 251, 'canvas': 252, 'canvases': 253, 'cards': 254, 'care': 255, 'career': 256, 'caught': 257, 'central': 258, 'chair': 259, 'chap': 260, 'characteristic': 261, 'charming': 262, 'cheap': 263, 'check': 264, 'cheeks': 265, 'chest': 266, 'chimney-piece': 267, 'chucked': 268, 'cigar': 269, 'cigarette': 270, 'cigars': 271, 'circulation': 272, 'circumstance': 273, 'circus-clown': 274, 'claimed': 275, 'clasping': 276, 'clear': 277, 'cleverer': 278, 'close': 279, 'clue': 280, 'coat': 281, 'collapsed': 282, 'colour': 283, 'come': 284, 'comfortable': 285, 'coming': 286, 'companion': 287, 'compared': 288, 'complex': 289, 'confident': 290, 'congesting': 291, 'conjugal': 292, 'constraint': 293, 'consummate': 294, 'contended': 295, 'continued': 296, 'corner': 297, 'corrected': 298, 'could': 299, 'couldn': 300, 'count': 301, 'countenance': 302, 'couple': 303, 'course': 304, 'covered': 305, 'craft': 306, 'cried': 307, 'crossed': 308, 'crowned': 309, 'crumbled': 310, 'cry': 311, 'cured': 312, 'curiosity': 313, 'curious': 314, 'current': 315, 'curtains': 316, 'd': 317, 'dabble': 318, 'damask': 319, 'dark': 320, 'dashed': 321, 'day': 322, 'days': 323, 'dead': 324, 'deadening': 325, 'dear': 326, 'deep': 327, 'deerhound': 328, 'degree': 329, 'delicate': 330, 'demand': 331, 'denied': 332, 'deploring': 333, 'deprecating': 334, 'deprecatingly': 335, 'desire': 336, 'destroyed': 337, 'destruction': 338, 'desultory': 339, 'detail': 340, 'diagnosis': 341, 'did': 342, 'didn': 343, 'died': 344, 'dim': 345, 'dimmest': 346, 'dingy': 347, 'dining-room': 348, 'disarming': 349, 'discovery;': 350, 'discrimination': 351, 'discussion': 352, 'disdain': 353, 'disdained': 354, 'disease': 355, 'disguised': 356, 'display': 357, 'dissatisfied': 358, 'distinguished': 359, 'distract': 360, 'divert': 361, 'do': 362, 'doesn': 363, 'doing': 364, 'domestic': 365, 'don': 366, 'done': 367, 'donkey': 368, 'down': 369, 'dozen': 370, 'dragged': 371, 'drawing-room': 372, 'drawing-rooms': 373, 'drawn': 374, 'dress-closets': 375, 'drew': 376, 'dropped': 377, 'each': 378, 'earth': 379, 'ease': 380, 'easel': 381, 'easy': 382, 'echoed': 383, 'economy': 384, 'effect': 385, 'effects': 386, 'efforts': 387, 'egregious': 388, 'eighteenth-century': 389, 'elbow': 390, 'elegant': 391, 'else': 392, 'embarrassed': 393, 'enabled': 394, 'end': 395, 'endless': 396, 'enjoy': 397, 'enlightenment:': 398, 'enough': 399, 'ensuing': 400, 'equally': 401, 'equanimity': 402, 'escape': 403, 'established': 404, 'etching': 405, 'even': 406, 'event': 407, 'ever': 408, 'everlasting': 409, 'every': 410, 'exasperated': 411, 'except': 412, 'excuse': 413, 'excusing': 414, 'existed': 415, 'expected': 416, 'exquisite': 417, 'exquisitely': 418, 'extenuation': 419, 'exterminating': 420, 'extracting': 421, 'eye': 422, 'eyebrows': 423, 'eyes': 424, 'eyes:': 425, 'face': 426, 'faces': 427, 'fact': 428, 'faded': 429, 'failed': 430, 'failure': 431, 'fair': 432, 'faith': 433, 'false': 434, 'familiar': 435, 'famille-verte': 436, 'fancy': 437, 'fashionable': 438, 'fate': 439, 'feather': 440, 'feet': 441, 'fell': 442, 'fellow': 443, 'felt': 444, 'few': 445, 'fewer': 446, 'finality': 447, 'find': 448, 'fingers': 449, 'first': 450, 'fit': 451, 'fitting': 452, 'five': 453, 'flash': 454, 'flashed': 455, 'florid': 456, 'flowers': 457, 'fluently': 458, 'flung': 459, 'follow': 460, 'followed': 461, 'fond': 462, 'footstep': 463, 'for': 464, 'forced': 465, 'forcing': 466, 'forehead': 467, 'foreign': 468, 'foreseen': 469, 'forgive': 470, 'forgotten': 471, 'form': 472, 'formed': 473, 'forming': 474, 'forward': 475, 'fostered': 476, 'found': 477, 'foundations': 478, 'fragment': 479, 'fragments': 480, 'frame': 481, 'frames': 482, 'frequently': 483, 'friend': 484, 'from': 485, 'full': 486, 'fullest': 487, 'furiously': 488, 'furrowed': 489, 'garlanded': 490, 'garlands': 491, 'gave': 492, 'genial': 493, 'genius': 494, 'gesture': 495, 'get': 496, 'getting': 497, 'give': 498, 'given': 499, 'glad': 500, 'glanced': 501, 'glimpse': 502, 'gloried': 503, 'glory': 504, 'go': 505, 'going': 506, 'gone': 507, 'good': 508, 'good-breeding': 509, 'good-humoured': 510, 'got': 511, 'grace': 512, 'gradually': 513, 'gray': 514, 'grayish': 515, 'great': 516, 'greatest': 517, 'greatness': 518, 'grew': 519, 'groping': 520, 'growing': 521, 'had': 522, 'hadn': 523, 'hair': 524, 'half': 525, 'half-light': 526, 'half-mechanically': 527, 'hall': 528, 'hand': 529, 'hands': 530, 'handsome': 531, 'hanging': 532, 'happen': 533, 'happened': 534, 'hard': 535, 'hardly': 536, 'has': 537, 'have': 538, 'haven': 539, 'having': 540, 'he': 541, 'head': 542, 'hear': 543, 'heard': 544, 'heart': 545, 'height': 546, 'her': 547, 'here': 548, 'here;': 549, 'hermit': 550, 'herself': 551, 'hesitations': 552, 'hide': 553, 'high': 554, 'him': 555, 'him:': 556, 'himself': 557, 'hint': 558, 'his': 559, 'history': 560, 'holding': 561, 'home': 562, 'honour': 563, 'hooded': 564, 'hostess': 565, 'hostess:': 566, 'hot-house': 567, 'hour': 568, 'hours': 569, 'house': 570, 'how': 571, 'hung': 572, 'husband': 573, 'idea': 574, 'idle': 575, 'idling': 576, 'if': 577, 'immediately': 578, 'in': 579, 'incense': 580, 'indifferent;': 581, 'inevitable': 582, 'inevitably': 583, 'inflexible': 584, 'insensible': 585, 'insignificant': 586, 'instinctively': 587, 'instructive': 588, 'interesting': 589, 'into': 590, 'ironic': 591, 'irony': 592, 'irrelevance': 593, 'irrevocable': 594, 'is': 595, 'it': 596, 'it;': 597, 'its': 598, 'itself': 599, 'jardiniere': 600, 'jealousy': 601, 'just': 602, 'keep': 603, 'kept': 604, 'kind': 605, 'knees': 606, 'knew': 607, 'know': 608, 'know;': 609, 'known': 610, 'laid': 611, 'lair': 612, 'landing': 613, 'language': 614, 'last': 615, 'late': 616, 'later': 617, 'latter': 618, 'laugh': 619, 'laugh:': 620, 'laughed': 621, 'lay': 622, 'leading': 623, 'lean': 624, 'learned': 625, 'least': 626, 'leathery:': 627, 'leave': 628, 'led': 629, 'left': 630, 'leisure': 631, 'lends': 632, 'lent': 633, 'let': 634, 'lies': 635, 'life': 636, 'life-likeness': 637, 'lift': 638, 'lifted': 639, 'light': 640, 'lightly;': 641, 'like': 642, 'liked': 643, 'line': 644, 'lines': 645, 'lingered': 646, 'lips': 647, 'lit': 648, 'little': 649, 'little:': 650, 'live': 651, 'll': 652, 'loathing': 653, 'long': 654, 'longed': 655, 'longer': 656, 'look': 657, 'looked': 658, 'looking': 659, 'lose': 660, 'loss': 661, 'lounging': 662, 'lovely': 663, 'lucky': 664, 'lump': 665, 'luncheon-table': 666, 'luxury': 667, 'lying': 668, 'made': 669, 'make': 670, 'man': 671, 'manage': 672, 'managed': 673, 'mantel-piece': 674, 'marble': 675, 'married': 676, 'may': 677, 'me': 678, 'meant': 679, 'mediocrity': 680, 'medium': 681, 'mentioned': 682, 'mere': 683, 'merely': 684, 'met': 685, 'might': 686, 'mighty': 687, 'millionaire': 688, 'mine': 689, 'mine:': 690, 'minute': 691, 'minutes': 692, 'mirrors': 693, 'modest': 694, 'modesty': 695, 'moment': 696, 'money': 697, 'monumental': 698, 'mood': 699, 'morbidly': 700, 'more': 701, 'most': 702, 'mourn': 703, 'mourned': 704, 'moustache': 705, 'moved': 706, 'much': 707, 'muddling;': 708, 'multiplied': 709, 'murmur': 710, 'muscles': 711, 'must': 712, 'my': 713, 'myself': 714, 'mysterious': 715, 'naive': 716, 'near': 717, 'nearly': 718, 'negatived': 719, 'nervous': 720, 'nervousness;': 721, 'neutral': 722, 'never': 723, 'next': 724, 'no': 725, 'none': 726, 'not': 727, 'note': 728, 'nothing': 729, 'now': 730, 'nymphs': 731, 'oak': 732, 'obituary': 733, 'object': 734, 'objects': 735, 'occurred': 736, 'oddly': 737, 'of': 738, 'off': 739, 'often': 740, 'oh': 741, 'old': 742, 'on': 743, 'once': 744, 'one': 745, 'ones': 746, 'only': 747, 'onto': 748, 'open': 749, 'or': 750, 'other': 751, 'our': 752, 'ourselves': 753, 'out': 754, 'out:': 755, 'outline': 756, 'oval': 757, 'over': 758, 'own': 759, 'packed': 760, 'paid': 761, 'paint': 762, 'painted': 763, 'painted;': 764, 'painter': 765, 'painting': 766, 'painting;': 767, 'pale': 768, 'paled': 769, 'palm-trees;': 770, 'panel': 771, 'panelling': 772, 'pardonable': 773, 'pardoned': 774, 'part': 775, 'passages': 776, 'passing': 777, 'past': 778, 'pastels': 779, 'pathos': 780, 'patient': 781, 'people': 782, 'perceptible': 783, 'perfect': 784, 'persistence': 785, 'persuasively': 786, 'phrase': 787, 'picture': 788, 'pictures': 789, 'pines': 790, 'pink': 791, 'place': 792, 'placed': 793, 'plain': 794, 'platitudes': 795, 'pleased': 796, 'pockets': 797, 'point': 798, 'poised': 799, 'poor': 800, 'portrait': 801, 'posing': 802, 'possessed': 803, 'poverty': 804, 'predicted': 805, 'preliminary': 806, 'presenting': 807, 'prestidigitation': 808, 'pretty': 809, 'previous': 810, 'price': 811, 'pride': 812, 'pride:': 813, 'princely': 814, 'prism': 815, 'problem': 816, 'proclaiming': 817, 'prodigious': 818, 'profusion': 819, 'protest': 820, 'prove': 821, 'public': 822, 'purblind': 823, 'purely': 824, 'pushed': 825, 'put': 826, 'qualities': 827, 'quality': 828, 'queerly': 829, 'question': 830, 'question:': 831, 'quickly': 832, 'quietly': 833, 'quite': 834, 'quote': 835, 'rain': 836, 'raised': 837, 'random': 838, 'rather': 839, 're': 840, 'real': 841, 'really': 842, 'reared': 843, 'reason': 844, 'reassurance': 845, 'recovering': 846, 'recreated': 847, 'reflected': 848, 'reflection': 849, 'regrets': 850, 'relatively': 851, 'remained': 852, 'remember': 853, 'reminded': 854, 'repeating': 855, 'represented': 856, 'reproduction': 857, 'resented': 858, 'resolve': 859, 'resources': 860, 'rest': 861, 'rich': 862, 'rich;': 863, 'ridiculous': 864, 'robbed': 865, 'romantic': 866, 'room': 867, 'rose': 868, 'rs': 869, 'rule': 870, 'run': 871, 's': 872, 'said': 873, 'said:': 874, 'same': 875, 'satisfaction': 876, 'satisfaction:': 877, 'savour': 878, 'saw': 879, 'say': 880, 'say:': 881, 'saying': 882, 'says': 883, 'scorn': 884, 'scornful': 885, 'secret': 886, 'see': 887, 'seemed': 888, 'seen': 889, 'self-confident': 890, 'send': 891, 'sensation': 892, 'sensitive': 893, 'sent': 894, 'serious': 895, 'set': 896, 'sex': 897, 'shade': 898, 'shaking': 899, 'shall': 900, 'she': 901, 'shirked': 902, 'short': 903, 'should': 904, 'shoulder': 905, 'shoulders': 906, 'show': 907, 'showed': 908, 'showy': 909, 'shrug': 910, 'shrugged': 911, 'sight': 912, 'sign': 913, 'silent;': 914, 'silver': 915, 'similar': 916, 'simpleton': 917, 'simplifications': 918, 'simply': 919, 'since': 920, 'single': 921, 'sitter': 922, 'sitters': 923, 'sketch': 924, 'skill': 925, 'slight': 926, 'slightly': 927, 'slowly:': 928, 'small': 929, 'smile': 930, 'smiling': 931, 'sneer': 932, 'so': 933, 'solace': 934, 'some': 935, 'somebody': 936, 'something': 937, 'spacious': 938, 'spaniel': 939, 'speaking-tubes': 940, 'speculations;': 941, 'spite': 942, 'splash': 943, 'square': 944, 'stairs': 945, 'stammer': 946, 'stand': 947, 'standing': 948, 'started': 949, 'stay': 950, 'still': 951, 'stocked': 952, 'stood': 953, 'stopped': 954, 'stopping': 955, 'straddling': 956, 'straight': 957, 'strain': 958, 'straining': 959, 'strange': 960, 'straw': 961, 'stream': 962, 'stroke': 963, 'strokes': 964, 'strolled': 965, 'strongest': 966, 'strongly': 967, 'struck': 968, 'studio': 969, 'stuff': 970, 'subject': 971, 'substantial': 972, 'suburban': 973, 'such': 974, 'suddenly': 975, 'suffered': 976, 'sugar': 977, 'suggested': 978, 'sunburn': 979, 'sunburnt': 980, 'sunlit': 981, 'superb': 982, 'sure': 983, 'surest': 984, 'surface': 985, 'surprise': 986, 'surprised': 987, 'surrounded': 988, 'suspected': 989, 'sweetly': 990, 'sweetness': 991, 'swelling': 992, 'swept': 993, 'swum': 994, 't': 995, 'table': 996, 'take': 997, 'taken': 998, 'talking': 999, 'tea': 1000, 'tears': 1001, 'technicalities': 1002, 'technique': 1003, 'tell': 1004, 'tells': 1005, 'tempting': 1006, 'terra-cotta': 1007, 'terrace': 1008, 'terraces': 1009, 'terribly': 1010, 'than': 1011, 'that': 1012, 'the': 1013, 'their': 1014, 'them': 1015, 'then': 1016, 'there': 1017, 'therefore': 1018, 'they': 1019, 'thin': 1020, 'thing': 1021, 'things': 1022, 'think': 1023, 'this': 1024, 'thither': 1025, 'those': 1026, 'though': 1027, 'thought': 1028, 'thought:': 1029, 'three': 1030, 'threshold': 1031, 'threw': 1032, 'through': 1033, 'throwing': 1034, 'tie': 1035, 'till': 1036, 'time': 1037, 'timorously': 1038, 'tinge': 1039, 'tips': 1040, 'tired': 1041, 'to': 1042, 'told': 1043, 'tone': 1044, 'tones': 1045, 'too': 1046, 'took': 1047, 'tottering': 1048, 'touched': 1049, 'toward': 1050, 'trace': 1051, 'trade': 1052, 'transmute': 1053, 'traps': 1054, 'travelled': 1055, 'tribute': 1056, 'tributes': 1057, 'tricks': 1058, 'tried': 1059, 'trouser-presses': 1060, 'true': 1061, 'truth': 1062, 'turned': 1063, 'twenty': 1064, 'twenty-four': 1065, 'twice': 1066, 'twirling': 1067, 'unaccountable': 1068, 'uncertain': 1069, 'under': 1070, 'underlay': 1071, 'underneath': 1072, 'understand': 1073, 'unexpected': 1074, 'untouched': 1075, 'unusual': 1076, 'up': 1077, 'up-stream': 1078, 'up;': 1079, 'upon': 1080, 'upset': 1081, 'upstairs': 1082, 'us': 1083, 'used': 1084, 'usual': 1085, 'value': 1086, 'varnishing': 1087, 'vases': 1088, 've': 1089, 'veins': 1090, 'velveteen': 1091, 'very': 1092, 'villa': 1093, 'vindicated': 1094, 'virtuosity': 1095, 'vista': 1096, 'vocation': 1097, 'voice': 1098, 'wall': 1099, 'wander': 1100, 'want': 1101, 'wanted': 1102, 'wants': 1103, 'was': 1104, 'wasn': 1105, 'watched': 1106, 'watching': 1107, 'water-colour': 1108, 'waves': 1109, 'way': 1110, 'weekly': 1111, 'weeks': 1112, 'welcome': 1113, 'went': 1114, 'were': 1115, 'what': 1116, 'when': 1117, 'whenever': 1118, 'where': 1119, 'which': 1120, 'while': 1121, 'white': 1122, 'white-panelled': 1123, 'who': 1124, 'whole': 1125, 'whom': 1126, 'why': 1127, 'wide': 1128, 'widow': 1129, 'wife': 1130, 'wild': 1131, 'wincing': 1132, 'wincing;': 1133, 'window-curtains': 1134, 'wish': 1135, 'with': 1136, 'without': 1137, 'wits': 1138, 'woman': 1139, 'women': 1140, 'women:': 1141, 'won': 1142, 'wonder': 1143, 'wondered': 1144, 'word': 1145, 'work': 1146, 'working': 1147, 'worth': 1148, 'would': 1149, 'wouldn': 1150, 'year': 1151, 'years': 1152, 'yellow': 1153, 'yet': 1154, 'you': 1155, 'younger': 1156, 'your': 1157, 'yourself': 1158, '<|endoftext|>': 1159, '<|unk|>': 1160}\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "all_words.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab_size = len(all_words)\n",
    "print(\"Vocabulary size: \", vocab_size)\n",
    "# assign a unique integer to each word\n",
    "vocab = {token: integer for integer, token in enumerate(all_words)}\n",
    "print(\"Vocabulary: \", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?!\"\\'()_]|--|\\s)', text)\n",
    "        preprocessed = [item for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[token] for token in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n",
      "[1160, 5, 362, 1155, 642, 1000, 10, 1159, 57, 1013, 981, 1009, 738, 1013, 1160, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)\n",
    "\n",
    "tokenizer = SimpleTokenizer(vocab)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we're using BPE to encode and decode text\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "enc_text = tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a dataset for batched inputs and targets\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i+1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(txt, batch_size=4, max_length=256, \n",
    "                      stride=128, shuffle=True, drop_last=True, \n",
    "                      num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            shuffle=shuffle, drop_last=drop_last, \n",
    "                            num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "\n",
    "# token embedding\n",
    "output_dim = 256\n",
    "vocab_size = 50257\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "inputs, targets = next(data_iter)\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "\n",
    "# positional embedding\n",
    "context_length = 4\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "\n",
    "# input embedding\n",
    "input_embedding = token_embeddings + pos_embeddings\n",
    "print(input_embedding.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
